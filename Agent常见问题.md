# RAG检索引擎
## 标准工作流
1. 数据准备：清洗与分块->向量化->入库
2. 检索：问题向量化->相似度检索->混合检索（关键词检索（BM25）及向量检索（语义））
3. 重排序：准确率提升关键，Rerank模型对初选出的top20-50等片段进行深度打分，选出top3-5
4. 生成：提示词工程、LLM推理（读资料、写答案）
5. 溯源：回答中标记来源
## RAG准确度提升方案
1. 检索前增强：查询重写、多查询生成、HyDE（假设性文档嵌入）
2. 检索中增强：混合检索、父子分块（检索子块返回父块，保证上下文完整）
3. **检索后增强**：最有效步骤，重排序、上下文压缩（保留召回文本核心语句，减少大模型干扰和节省token）
4. 其他：GraphRAG（图增强检索，搜索全局信息）、Agentic RAG（LLM自我反思和调用工具）
## RAG性能及高并发设计
RAG性能提升本质是多阶段瓶颈优化的过程，链路涉及CPU（业务逻辑）、I/O（数据库检索）、GPU（模型推理）

- 架构设计：解耦与异步化
  - 微服务化与水平扩展：RAG拆为接入层、检索层、重排序层、推理层，独立部署支持自动扩缩容
  - 异步化与流式响应：流式输出、非即时反馈场景通过消息队列削峰填谷
  - 负载均衡：nginx等高性能负载均衡
- 检索层：读写分离与只读副本、索引分片&并行计算（数据量极大）、索引优化（使用HNSW、IVF-PQ索引）、并行混合检索
- 模型工程：Embedding模型、**Rerank模型**、LLM模型，推理加速后端->模型量化与蒸馏->模型网关&多实例调度
- 缓存机制：最高效手段，**语义缓存（语义与历史问题相似）**、传统结果缓存（Embedding结果、Rerank结果等）、预拉取机制（根据用户对话，提前异步加载可能相关的文档片段）
- 性能指标监控：TPOT（Time Per Output Token, 每个token生成速度）、TTFT（Time To First Token, 首字延迟，用户体验核心）、QPS、召回准确率监控

### 高并发RAG标准链路
请求进入（负载均衡）-> 语义缓存检查 -> 并行处理（计算Embedding、从Redis获取上下文）-> 检索只读副本 -> Rerank（top50结果GPU加速精排）-> LLM推理（vLLM队列，连续批处理生成答案）-> 流式返回（SSE协议）
## RAG快速召回算法，近似最近邻算法-ANN
- HNSW 算法（分层导航小世界图）：基于图结构，目前最主流
- IVF（倒排文件索引）：利用K-Means算法将向量划为N个簇，根据簇中心距离缩小规模
- PQ（乘积量化）：高维向量划分为子向量并进行压缩（量化），节省内存（10-100倍），支持查表快速估算
  
